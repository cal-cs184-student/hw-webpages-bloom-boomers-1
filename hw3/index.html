<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: </div>

		<br>

		Link to webpage: (TODO) <a href="https://cs184.eecs.berkeley.edu/sp25">cs184.eecs.berkeley.edu/sp25</a>
		Link to GitHub repository: (TODO) <a href="https://cs184.eecs.berkeley.edu/sp25">cs184.eecs.berkeley.edu/sp25</a>
		
		<figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure>

		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		In this homework we learned how to apply multiple sampling techniques as well as how to apply global illumination. 

		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		<ul>
			<li>
				First we create the transformation matrix to translate the coordinate input to camera space.
				We see in the diagram that in camera space, the bottom left corner of the camera space is at 
				(-tan(0.5 * hFov), -tan(0.5 * vFov), -1), while the upper corner is at (tan(0.5 * hFov), tan(0.5 * vFov), -1),
				so we choose the u and v vectors to be u = {2 * tan(radians(0.5 * hFov)), 0, 0} and v = {0, 2 * tan(radians(0.5 * vFov)), 0}.
				Then we pick our origin point as o = {-tan(radians(0.5 * hFov)), -tan(radians(0.5 * vFov)), 1}, thus we have our
				transformation matrix T. We tranform the input coordinates with T. We create a directional vector 
				dirVector = Vector3D(transformed_input.x, transformed_input.y, -1) and create the camera ray newRay. The camera ray
				has origin at (0,0,0) (camera space) and its direction is dirVector. We set the min_t to the camera's nClip and 
				max_t to the fClip. Lastly, we return a ray with origin at the camera's position, and direction set to 
				this->c2w * newRay.d.
			</li>
			<li>
				We used Möller Trumbore Algorithm from lecture. Using Möller Trumbore Algorithm we can solve for the unkowns
				[t, b1, b2], where t is the time of intersection, and b1 and b2 are barycentric coordinates we will use to
				calculate the normal of the triangle. We store [t, b1, b2] in the array result, where result[0] is t, 
				result[1] is b1, and result[2] is b2. From discussion, we determine if the ray intersected with the triangle
				by checking t >= 0, 0 <= b1 <= 1, 0 <= b2 <= 1, 0 <= 1 - b1 - b2 <= 1. If the ray intersected with the traingle,
				we set 
				r.max_t = result[0], 
				isect->t = result[0],
				isect->n = (1 - result[1] - result[2]) * this->n1 + result[1] * this->n2 + result[2] * this->n3,
				isect->n.normalize(),
				isect->primitive = this,
				isect->bsdf = this->get_bsdf(). 
				Lastly, we return true if the ray intersected with the triangle, false otherwise.
			</li>
		</ul>
		
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="pt1_empty.png" width="400px"/>
				</td>
				<td style="text-align: center;">
				  <img src="pt1_spheres.png" width="400px"/>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="pt1_gems.png" width="400px"/>
				</td>
				<td style="text-align: center;">
				  <img src="pt1_coil.png" width="400px"/>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		<ul>
			<li>In our BVH construction algorithm, we start by initializing (for the current node):
			  <ul>
				<li>Bounding box</li>
				<li>Minimum/maximum x, y, and z positions</li>
			  </ul>
			</li>
			<li>We then iterate through the primitives stored in each node of the BVH, starting from the root, to:
			  <ul>
				<li>Update the minimum/maximum positions when encountering a primitive whose centroid is less than the current minimum or greater than the current maximum.</li>
				<li>Increment a count of primitives in the current node</li>
				<li>Expand the bounding box to contain each primitive</li>
			  </ul>
			</li>
			<li>If the count of primitives is less than the maximum leaf size, the current node is a leaf, so we create a BVH leaf node with <code>l</code> and <code>r</code> set to <code>null</code>, and <code>start</code> and <code>end</code> set to the start and end values passed into the current function call. We then return this leaf node.</li>
			<li>Otherwise, we calculate the maximum difference between the minimum and maximum for each x, y, and z dimension. This is because the heuristic we’re using to determine how to split is choosing the dimension with the largest range of values. We then split at the midpoint of that dimension. We find the midpoint by:
			  <ul>
				<li>Partitioning the primitives into two groups: those with centroid position &lt; midpoint to the left, and the rest go to the right.</li>
				<li>Creating an iterator called <code>mid</code> which points to the first element of the right group</li>
			  </ul>
			</li>
			<li>At the end, we create a new inner node, where its left child is a recursive call to <code>construct_bvh(start, mid, max_leaf_size)</code> and its right child is <code>construct_bvh(mid, end, max_leaf_size)</code>. We return this inner node.</li>
			<li>To prevent infinite recursion, we check if <code>start == mid</code> or <code>mid == end</code>. If true, we return a leaf node since all primitives fall on the same side.</li>
		  </ul>
		  <div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
					<img src="max_planck.png" width="400px"/>
				</td>
				<td style="text-align: center;">
					<img src="lucy.png" width="400px"/>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
					<img src="beast.png" width="400px"/>
				</td>
				<td style="text-align: center;">
					<img src="peter.png" width="400px"/>
				</td>
			  </tr>
			</table>
		</div>		
		<div>
			<h2>With BVH</h2>
			<pre><code>
			[PathTracer] Collecting primitives... Done! (0.0029 sec)
			[PathTracer] Building BVH from 40018 primitives... Done! (0.0069 sec)
			[PathTracer] Rendering... 100%! (0.0347s)
			[PathTracer] BVH traced 199740 rays.
			[PathTracer] Average speed 5.7490 million rays per second.
			[PathTracer] Averaged 3.328587 intersection tests per ray.
			</code></pre>
		</div>
	
		<div>
			<h2>Without BVH</h2>
			<pre><code>
			[PathTracer] Collecting primitives... Done! (0.0019 sec)
			[PathTracer] Building BVH from 40018 primitives... Done! (0.0000 sec)
			[PathTracer] Rendering... 100%! (38.7694s)
			[PathTracer] BVH traced 446839 rays.
			[PathTracer] Average speed 0.0115 million rays per second.
			[PathTracer] Averaged 8025.000535 intersection tests per ray.
			</code></pre>
		</div>

		<div> 
			When using BVH acceleration, the rendering is completed significantly faster. 
			This is because we are eliminating a lot of unnecessary intersection checking. 
			If a ray doesn’t intersect a parent bounding box, it is guaranteed to not intersect 
			its children bounding boxes and the primitives contained in its leaf nodes. 
			As a result, BVH acceleration doesn’t continue to check whether a ray intersects 
			the children or primitives of a bouncing box that it doesn’t intersect. 
			By eliminating these unnecessary checks, the rendering can happen much faster, 
			especially for complex geometries that result in many leave nodes due to the vast 
			number of primitives present.
		</div>
		  
		<h2>Part 3: Direct Illumination</h2>
		<ul>
			<li>
				<ul>
					<li>
						estimate_direct_lighting_hemisphere: For hemisphere sampling we sample a direction Vector num_samples 
						times using the function hemisphereSampler->get_sample(). Since the provided vector is in object space,
						we convert it world space by multiplying it by the o2w matrix, attaining our wi vector. We then create
						a ray at the provided hit_p, and direction wi (which has been converted to world space).
					</li>
					<li>
						estimate_direct_lighting_importance: Instead of sampling uniformly, with direct sampling we sample the
						light sources directly. For each light in the scene we do following loop: we sample the radiance vector
						num_samples times (note: we check if the light is a point light first, if it is num_samples = 1, else num_samples 
						= scene->lights.size() * ns_area_light). We sample the radiance using SceneLight::sample_L, which returns 
						a wi Vector, the distance to the light and the pdf as pointers. Then, using the returned wi, we cast a ray
						going from point hit_p, towards wi. If there's no intersection between the ray and the camera, we know light
						reaches the camera at that direction, so we sample the bsdf vector with isect.bsdf->f and add 
						(emitted_radiance * brdf * cos_theta(w2o * wi)) / pdf to L_out. We add num_samples to total_samples and 
						proceed to the next light. After we repeat that for all lights, we return L_out / total_samples. 
					</li>
					<li>
						As shown below, importance sampling yielding less noisy results than hemisphere sampling. In both
						images, soft shadows look much cleaner when using importance sampling. Hemisphere sampling was, however,
						faster than importance sampling.
					</li>
				</ul>
			</li>
		</ul>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="pt3_sphere_uniform.png" width="400px"/>
				  <figcaption>Uniform Hemisphere Sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pt3_sphere_importance.png" width="400px"/>
				  <figcaption>Importance Sampling</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="pt3_bunny_uniform.png" width="400px"/>
				  <figcaption>Uniform Hemisphere Sampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pt3_bunny_importance.png" width="400px"/>
				  <figcaption>Importance Sampling</figcaption>
				</td>
			  </tr>
			</table>
		</div>
			The screenshots below were taken after part 4, but we can still compare the soft shadows here. 
			Namely, if we focus on the shadow casted below the bunny, we can see that they become less noisy
			the more samples we use. For 1 sample, the shadow gets quite grainy as it spreads thinner. 
			Contrasting that with the 64 image, the shadow doesn't have nearly as much noise as it falls off.
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="pt3_bunny_1.png" width="400px"/>
				  <figcaption>1 light ray</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pt3_bunny_4.png" width="400px"/>
				  <figcaption>4 light rays</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="pt3_bunny_16.png" width="400px"/>
				  <figcaption>16 light rays</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pt3_bunny_64.png" width="400px"/>
				  <figcaption>64 light rays</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h2>Part 4: Global Illumination</h2>
		<div>
			<h3>Indirect Lighting Function Walkthrough</h3>  
			<p><code>at_least_one_bounce_radiance_helper</code>:</p>
			
			<ul>
				<li>1. If <code>depth == 0</code>, return <span class="highlight">black</span> since we don't consider light contribution beyond the maximum ray depth.</li>
				
				<li>2. Call <code>one_bounce_radiance(r, isect)</code> to compute <span class="highlight">direct lighting</span>.</li>
				
				<li>3. Sampling Indirect Lighting (If <code>depth > 1</code>):
					<ul>
						<li>Sample an incoming direction <code>wi</code> using the BSDF: <code>isect.bsdf->sample_f(w_out, &wi, &pdf)</code>.</li>
						<li>Convert <code>wi</code> to world space (<code>wi2w</code>) for the next bounce.</li>
						<li>Create a new <span class="highlight">sample ray</span> originating from the hit point <code>hit_p</code> in direction <code>wi2w</code>.</li>
					</ul>
				</li>
				
				<li>4. Russian Roulette Termination:
					<ul>
						<li>Use a coin flip (<code>coin_flip(cpdf)</code>) to decide whether to terminate.</li>
						<li>If the ray hits another surface, recursively compute <span class="highlight">indirect lighting</span> using <code>at_least_one_bounce_radiance(sample_ray, sample_isect)</code>.</li>
						<li>Compute the indirect radiance contribution using the rendering equation:
							<pre>L_indirect = (incoming_radiance * BSDF * cosθ) / (PDF * cpdf)</pre>
						</li>
						<li>Accumulate <code>L_out</code> if <code>isAccumBounces</code> is true. Otherwise, return the L value of the last ray.</li>
					</ul>
				</li>
				<li>
					With direct and indirect:
				</li>
				<li>
					<img src="spheres_part4_2.png" width="400px"/>
					<img src="bunny_part4_2.png" width="400px"/>
				</li>
				<li>
					Unaccumulated Bounces:
				</li>
				<li>
					m = 0
				</li>
				<li>
					<img src="bunny_part4_4_0.png" width="400px"/>
				</li>
				<li>
					m = 1
				</li>
				<li>
					<img src="bunny_part4_4_1.png" width="400px"/>
				</li>
				<li>
					m = 2
				</li>
				<li>
					<img src="bunny_part4_4_2.png" width="400px"/>
				</li>
				<li>
					m = 3
				</li>
				<li>
					<img src="bunny_part4_4_3.png" width="400px"/>
				</li>
				<li>
					m = 4
				</li>
				<li>
					<img src="bunny_part4_4_4.png" width="400px"/>
				</li>
				<li>
					m = 5
				</li>
				<li>
					<img src="bunny_part4_4_5.png" width="400px"/>
				</li>
				<li>
					Between the 2nd and 3rd bounce, the image seems darker on the 3rd bounce.
					The shadows look slightly darker overall. This indicates that the light
					dies off with each bounce, which contributes to the overall richness of the render,
					and also shows that pixels eventually converge.
				</li>
				<li>
					Accumulated Bounces:
				</li>
				<li>
					m = 0
				</li>
				<li>
					<img src="bunny_part4_4_0_1.png" width="400px"/>
				</li>
				<li>
					m = 1
				</li>
				<li>
					<img src="bunny_part4_4_1_1.png" width="400px"/>
				</li>
				<li>
					m = 2
				</li>
				<li>
					<img src="bunny_part4_4_2_1.png" width="400px"/>
				</li>
				<li>
					m = 3
				</li>
				<li>
					<img src="bunny_part4_4_3_1.png" width="400px"/>
				</li>
				<li>
					m = 4
				</li>
				<li>
					<img src="bunny_part4_4_4_1.png" width="400px"/>
				</li>
				<li>
					m = 5
				</li>
				<li>
					<img src="bunny_part4_4_5_1.png" width="400px"/>
				</li>
				<li>
					In comparison to accumulate, we see that with each bounce the change is much more
					subtle. Instead, when we accumulate with each bounce the room becomes more colorful
					because the indirect light from the walls and the bunny is bouncing off and accumulating 
					(for instance, there's more red on the ceiling at m = 5 compared to m = 2).
				</li>
				<li>
					Samples per pixel:
				</li>
				<li>
					1
				</li>
				<li>
					<img src="bunny_part4_6_1.png" width="400px"/>
				</li>
				<li>
					2
				</li>
				<li>
					<img src="bunny_part4_6_2.png" width="400px"/>
				</li>
				<li>
					4
				</li>
				<li>
					<img src="bunny_part4_6_4.png" width="400px"/>
				</li>
				<li>
					8
				</li>
				<li>
					<img src="bunny_part4_6_8.png" width="400px"/>
				</li>
				<li>
					16
				</li>
				<li>
					<img src="bunny_part4_6_16.png" width="400px"/>
				</li>
				<li>
					64
				</li>
				<li>
					<img src="bunny_part4_6_64.png" width="400px"/>
				</li>
				<li>
					1024
				</li>
				<li>
					<img src="bunny_part4_6_1024.png" width="400px"/>
				</li>
				<li>
					The number of samples per pixel direcly correlate with the level of noise in the pictures.
					If we look at 1 and compare to 1024 we see that the latter has almost no noise while the former
					has a considerable amount of noise.
				</li>
			</ul>
			
		</div>		
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="pt4_global_illum1.png" width="400px"/>
				</td>
				<td style="text-align: center;">
				  <img src="pt4_global_illum2.png" width="400px"/>
				</td>
			  </tr>
			</table>
		</div>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="direct_illumination_bunny.png" width="400px"/>
				  <figcaption>Direct Illumination</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pt4_global_illum2.png" width="400px"/>
				  <figcaption>Indirect Illumination</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<div>Direct lighting only displays the light that originates from the light source without any bounces, so all we see is
			the box where the light came from. However, the second image shows the surfaces, where the light bounced off
			of, so we see where the light traveled from the source.
		</div>
		<h2>Part 5: Adaptive Sampling</h2>
		<ul>
			<li>
				Before adaptive sampling, we used a fixed amount of samples per pixel, which resulted in noise. Adaptive
				sampling addresses that by using a variable number of samples per pixel, depending on whether the pixel
				has converged or not. This allows us to concentrate more samples on parts of the image that take longer
				to converge, while saving computation on parts that require less samples to converge. We followed the instructions 
				from the spec. We define double variables s1, s2, samples_so_far, mean, variance, and I. While
				I > maxTolerance * mean and samples_so_far < num_samples (which equals ns_aa) we repeat the following loop:
				we generate a camera ray samplesPerBatch times at (x / sampleBuffer.w, y / sampleBuffer.h). For each of those rays,
				we compute the radiance vector using est_radiance_global_illumination(sampleRay) and add the radiance vector to the
				total vector. Then we compute xk = radiance.illum() and set s1 += xk, and s2 += xk*xk, and also increment samples_so_far.
				After sampling, we set mean = s1 / samples_so_far, variance = (s2 - s1 * s1 / samples_so_far) / (samples_so_far - 1), and
				I = 1.96 * sqrt(variance) / sqrt(samples_so_far). This is the end of the loop iteration, so if I <= maxTolerance * mean
				or samples_so_far >= num_samples we will break out of the loop, if not we keep repeating until the pixel converges.
				Finally we update the pixel with total / samples_so_far and set sampleCountBuffer[x + y * sampleBuffer.w] = samples_so_far.
			</li>
		</ul>		
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="spheres.png" width="400px"/>
				</td>
				<td style="text-align: center;">
				  <img src="spheres_rate.png" width="400px"/>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="bunny.png" width="400px"/>
				</td>
				<td style="text-align: center;">
				  <img src="bunny_rate.png" width="400px"/>
				</td>
			  </tr>
			</table>
		</div>
		<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
		
		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>